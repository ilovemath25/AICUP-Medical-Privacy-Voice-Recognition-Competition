{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ffefad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from seqeval.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a12cbbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2id: {'O': 0, 'B-PATIENT': 1, 'I-PATIENT': 2, 'B-DOCTOR': 3, 'I-DOCTOR': 4, 'B-USERNAME': 5, 'I-USERNAME': 6, 'B-PERSONALNAME': 7, 'I-PERSONALNAME': 8, 'B-FAMILYNAME': 9, 'I-FAMILYNAME': 10, 'B-HOSPITAL': 11, 'I-HOSPITAL': 12, 'B-DEPARTMENT': 13, 'I-DEPARTMENT': 14, 'B-ROOM': 15, 'I-ROOM': 16, 'B-STREET': 17, 'I-STREET': 18, 'B-CITY': 19, 'I-CITY': 20, 'B-DISTRICT': 21, 'I-DISTRICT': 22, 'B-COUNTY': 23, 'I-COUNTY': 24, 'B-STATE': 25, 'I-STATE': 26, 'B-COUNTRY': 27, 'I-COUNTRY': 28, 'B-ZIP': 29, 'I-ZIP': 30, 'B-ORGANIZATION': 31, 'I-ORGANIZATION': 32, 'B-LOCATION-OTHER': 33, 'I-LOCATION-OTHER': 34, 'B-AGE': 35, 'I-AGE': 36, 'B-DATE': 37, 'I-DATE': 38, 'B-TIME': 39, 'I-TIME': 40, 'B-DURATION': 41, 'I-DURATION': 42, 'B-SET': 43, 'I-SET': 44, 'B-CONTACT': 45, 'I-CONTACT': 46, 'B-PHONE': 47, 'I-PHONE': 48, 'B-FAX': 49, 'I-FAX': 50, 'B-EMAIL': 51, 'I-EMAIL': 52, 'B-URL': 53, 'I-URL': 54, 'B-IPADDRESS': 55, 'I-IPADDRESS': 56, 'B-SOCIAL_SECURITY_NUMBER': 57, 'I-SOCIAL_SECURITY_NUMBER': 58, 'B-MEDICAL_RECORD_NUMBER': 59, 'I-MEDICAL_RECORD_NUMBER': 60, 'B-HEALTH_PLAN_NUMBER': 61, 'I-HEALTH_PLAN_NUMBER': 62, 'B-ACCOUNT_NUMBER': 63, 'I-ACCOUNT_NUMBER': 64, 'B-LICENSE_NUMBER': 65, 'I-LICENSE_NUMBER': 66, 'B-VEHICLE_ID': 67, 'I-VEHICLE_ID': 68, 'B-DEVICE_ID': 69, 'I-DEVICE_ID': 70, 'B-BIOMETRIC_ID': 71, 'I-BIOMETRIC_ID': 72, 'B-ID_NUMBER': 73, 'I-ID_NUMBER': 74}\n",
      "id2label: {0: 'O', 1: 'B-PATIENT', 2: 'I-PATIENT', 3: 'B-DOCTOR', 4: 'I-DOCTOR', 5: 'B-USERNAME', 6: 'I-USERNAME', 7: 'B-PERSONALNAME', 8: 'I-PERSONALNAME', 9: 'B-FAMILYNAME', 10: 'I-FAMILYNAME', 11: 'B-HOSPITAL', 12: 'I-HOSPITAL', 13: 'B-DEPARTMENT', 14: 'I-DEPARTMENT', 15: 'B-ROOM', 16: 'I-ROOM', 17: 'B-STREET', 18: 'I-STREET', 19: 'B-CITY', 20: 'I-CITY', 21: 'B-DISTRICT', 22: 'I-DISTRICT', 23: 'B-COUNTY', 24: 'I-COUNTY', 25: 'B-STATE', 26: 'I-STATE', 27: 'B-COUNTRY', 28: 'I-COUNTRY', 29: 'B-ZIP', 30: 'I-ZIP', 31: 'B-ORGANIZATION', 32: 'I-ORGANIZATION', 33: 'B-LOCATION-OTHER', 34: 'I-LOCATION-OTHER', 35: 'B-AGE', 36: 'I-AGE', 37: 'B-DATE', 38: 'I-DATE', 39: 'B-TIME', 40: 'I-TIME', 41: 'B-DURATION', 42: 'I-DURATION', 43: 'B-SET', 44: 'I-SET', 45: 'B-CONTACT', 46: 'I-CONTACT', 47: 'B-PHONE', 48: 'I-PHONE', 49: 'B-FAX', 50: 'I-FAX', 51: 'B-EMAIL', 52: 'I-EMAIL', 53: 'B-URL', 54: 'I-URL', 55: 'B-IPADDRESS', 56: 'I-IPADDRESS', 57: 'B-SOCIAL_SECURITY_NUMBER', 58: 'I-SOCIAL_SECURITY_NUMBER', 59: 'B-MEDICAL_RECORD_NUMBER', 60: 'I-MEDICAL_RECORD_NUMBER', 61: 'B-HEALTH_PLAN_NUMBER', 62: 'I-HEALTH_PLAN_NUMBER', 63: 'B-ACCOUNT_NUMBER', 64: 'I-ACCOUNT_NUMBER', 65: 'B-LICENSE_NUMBER', 66: 'I-LICENSE_NUMBER', 67: 'B-VEHICLE_ID', 68: 'I-VEHICLE_ID', 69: 'B-DEVICE_ID', 70: 'I-DEVICE_ID', 71: 'B-BIOMETRIC_ID', 72: 'I-BIOMETRIC_ID', 73: 'B-ID_NUMBER', 74: 'I-ID_NUMBER'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"tag.txt\", \"r\") as f:\n",
    "    base_labels = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "label_list = [\"O\"]\n",
    "for label in base_labels:\n",
    "    label_list.append(f\"B-{label}\")\n",
    "    label_list.append(f\"I-{label}\")\n",
    "\n",
    "label2id = {label: idx for idx, label in enumerate(label_list)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "print(\"label2id:\", label2id)\n",
    "print(\"id2label:\", id2label)\n",
    "\n",
    "with open(\"combined_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    training_data = json.load(f)\n",
    "\n",
    "dataset = Dataset.from_list(training_data)\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = dataset[\"train\"]\n",
    "val_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b5dd83be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"bert-base-cased\"\n",
    "# model_path = \"../model/ner_shi_model\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path, num_labels=len(label_list), id2label=id2label, label2id=label2id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7b2b7682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    true_labels = []\n",
    "    true_predictions = []\n",
    "\n",
    "    for pred, label in zip(predictions, labels):\n",
    "        true_labels_example = []\n",
    "        true_predictions_example = []\n",
    "        for p_val, l_val in zip(pred, label):\n",
    "            if l_val != -100:\n",
    "                true_labels_example.append(id2label[l_val])\n",
    "                true_predictions_example.append(id2label[p_val])\n",
    "        true_labels.append(true_labels_example)\n",
    "        true_predictions.append(true_predictions_example)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(true_labels, true_predictions),\n",
    "        \"precision\": precision_score(true_labels, true_predictions),\n",
    "        \"recall\": recall_score(true_labels, true_predictions),\n",
    "        \"f1\": f1_score(true_labels, true_predictions)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b5a12ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c955362a2394d439a3cb97da173f444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/307 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a1c70940084a8997d99332620efad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/77 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "980a6507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_43892\\2767479498.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../model/ner_shi_model_checkpoint\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=25,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "167ec3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='390' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [390/390 1:01:22, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.609000</td>\n",
       "      <td>0.082575</td>\n",
       "      <td>0.987923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.055320</td>\n",
       "      <td>0.986175</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.393939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.046264</td>\n",
       "      <td>0.988241</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.403509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.044412</td>\n",
       "      <td>0.987446</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.379310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.042342</td>\n",
       "      <td>0.989194</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.044220</td>\n",
       "      <td>0.989035</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.522388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.044411</td>\n",
       "      <td>0.987923</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.546584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.047328</td>\n",
       "      <td>0.988877</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.047987</td>\n",
       "      <td>0.988718</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.566038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.048519</td>\n",
       "      <td>0.988718</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.573248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=390, training_loss=0.06650670507015326, metrics={'train_runtime': 3696.663, 'train_samples_per_second': 0.83, 'train_steps_per_second': 0.106, 'total_flos': 802710473472000.0, 'train_loss': 0.06650670507015326, 'epoch': 10.0})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f01d2bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../model/ner_shi_model\\\\tokenizer_config.json',\n",
       " '../model/ner_shi_model\\\\special_tokens_map.json',\n",
       " '../model/ner_shi_model\\\\vocab.txt',\n",
       " '../model/ner_shi_model\\\\added_tokens.json',\n",
       " '../model/ner_shi_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = \"../model/ner_shi_model\"\n",
    "if os.path.exists(model_dir):\n",
    "    shutil.rmtree(model_dir)\n",
    "trainer.save_model(model_dir)\n",
    "tokenizer.save_pretrained(model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
